{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "main = os.chdir(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from model import model_architecture, output_results, utils\n",
    "from sksurv.util import Surv as skSurv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Simulation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first choose the type of pseudo-observation among the followings:\n",
    "- \"pseudo_optim\"\n",
    "- \"pseudo_km\"\n",
    "- \"pseudo-discrete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"pseudo_optim\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the censoring rate of the simulated data (it can be either 0.2  or 0.6). Data is simulated by the random function generator introduced by Friedman et al. (2001). \n",
    "Data is normalized (with mean and std from train set for train and test set) and splitted into training and test set (df_train and df_test are subsets of df_sim). The same training and test set are used for all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_sim = \"data/simulations/\"+str(rate)+\"/\"\n",
    "\n",
    "df_sim = pd.read_csv(dir_sim+'simdata.csv')\n",
    "df_train = pd.read_csv(dir_sim+'sim_train.csv')\n",
    "df_test = pd.read_csv(dir_sim+'sim_test.csv')\n",
    "y_train = pd.read_csv(dir_sim+name+ \"_\" + str(rate) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all, y_train_all, x_test_all, y_test_all, n_picktime = utils.prepare_pseudobs_simu(df_train, y_train, df_test,name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained using the best parameters determined by a 5 folds cross validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = pd.read_csv('model/best_param_simu/'+name+'_best_param.csv', sep = \";\",index_col=0)\n",
    "    \n",
    "model,callbacks  = model_architecture.build_model_pseudobs(x_train_all, \n",
    "                           param['neurons'][rate], \n",
    "                           param['dropout'][rate], \n",
    "                           param['activation'][rate],\n",
    "                           param['lr'][rate],\n",
    "                           param['optimizer'][rate],\n",
    "                           param['n_layers'][rate],\n",
    "                              100)\n",
    "\n",
    "history = model.fit(x_train_all, \n",
    "         y_train_all, \n",
    "\n",
    "         int(param['batch_size'][rate]), \n",
    "                    epochs = 100,\n",
    "         callbacks = callbacks, \n",
    "         verbose = 0)\n",
    "\n",
    "y_pred = model.predict(x_test_all)\n",
    "y_pred = y_pred.reshape((n_picktime,len(df_test)))\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "\n",
    "if name == \"pseudo_discrete\" or name == \"pseudo_optim2\":\n",
    "    y_pred_all = pd.DataFrame()\n",
    "    for j in range(len(y_pred.columns)):    \n",
    "        for i in range(len(y_pred)):\n",
    "            y_pred_all.loc[i,j] = y_pred.loc[:i,j].prod(axis = 0)\n",
    "            surv = y_pred_all\n",
    "else:\n",
    "    surv = y_pred\n",
    "\n",
    "surv = surv.set_index(np.unique(y_train[['s']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We output the C-index at median time and the Integrated Brier Score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_median</th>\n",
       "      <th>ibs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868813</td>\n",
       "      <td>0.104529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_median       ibs\n",
       "0  0.868813  0.104529"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = output_results.output_sim_data(model,surv,x_train_all, df_train, x_test_all, df_test)\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
